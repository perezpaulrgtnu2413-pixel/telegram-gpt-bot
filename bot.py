import os
import logging
import tempfile
import cv2
import numpy as np
from dotenv import load_dotenv
from openai import OpenAI
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters
)

# -----------------------------------------------------
# üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏
# -----------------------------------------------------
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

client = OpenAI(api_key=OPENAI_API_KEY)

logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# -----------------------------------------------------
# ‚öôÔ∏è –ö–æ–º–∞–Ω–¥—ã
# -----------------------------------------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    context.user_data["voice_enabled"] = True
    text = (
        f"üëã –ü—Ä–∏–≤–µ—Ç, {user.first_name}!\n\n"
        "–Ø ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ GPT-4o.\n"
        "–û—Ç–ø—Ä–∞–≤—å üì∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–≠–ö–ì, –∞–Ω–∞–ª–∏–∑, —Ä–µ–Ω—Ç–≥–µ–Ω), üé§ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ üí¨ —Ç–µ–∫—Å—Ç ‚Äî —è –ø–æ–º–æ–≥—É —Å –∞–Ω–∞–ª–∏–∑–æ–º.\n\n"
        "üó£ –û–∑–≤—É—á–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤: –≤–∫–ª—é—á–µ–Ω–∞. –ö–æ–º–∞–Ω–¥—ã:\n"
        "/voice_off ‚Äî –æ—Ç–∫–ª—é—á–∏—Ç—å –∑–≤—É–∫\n"
        "/voice_on ‚Äî –≤–∫–ª—é—á–∏—Ç—å –∑–≤—É–∫"
    )
    keyboard = [[InlineKeyboardButton("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –¥–∏–∞–ª–æ–≥", callback_data="reset")]]
    await update.message.reply_text(text, reply_markup=InlineKeyboardMarkup(keyboard))


async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    await update.callback_query.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω ‚úÖ")
    await update.callback_query.edit_message_text("–î–∏–∞–ª–æ–≥ —Å–±—Ä–æ—à–µ–Ω. –ù–∞—á–Ω—ë–º –∑–∞–Ω–æ–≤–æ!")


async def voice_on(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["voice_enabled"] = True
    await update.message.reply_text("üîä –û–∑–≤—É—á–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞ ‚Äî —Ç–µ–ø–µ—Ä—å —è –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–º!")


async def voice_off(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["voice_enabled"] = False
    await update.message.reply_text("üîá –û–∑–≤—É—á–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞.")


# -----------------------------------------------------
# üí¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
# -----------------------------------------------------
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    history = context.user_data.get("history", [])
    history.append({"role": "user", "content": user_message})
    context.user_data["history"] = history[-10:]

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=history
        )
        reply_text = response.choices[0].message.content.strip()
        history.append({"role": "assistant", "content": reply_text})
        context.user_data["history"] = history[-10:]

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
        await update.message.reply_text(reply_text)

        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –æ–∑–≤—É—á–∫–∞ ‚Äî —Å–æ–∑–¥–∞—ë–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ
        if context.user_data.get("voice_enabled", True):
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_audio:
                audio_path = temp_audio.name

            # üé§ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—á–∏ —á–µ—Ä–µ–∑ OpenAI
            with client.audio.speech.with_streaming_response.create(
                model="gpt-4o-mini-tts",
                voice="alloy",
                input=reply_text
            ) as stream:
                stream.stream_to_file(audio_path)

            await update.message.reply_voice(voice=InputFile(audio_path))
            os.remove(audio_path)

    except Exception as e:
        logger.error(e)
        await update.message.reply_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")


# -----------------------------------------------------
# üéß –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (Whisper)
# -----------------------------------------------------
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as temp_file:
            file_path = temp_file.name
            await file.download_to_drive(custom_path=file_path)

        with open(file_path, "rb") as audio:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio
            )

        os.remove(file_path)
        text = transcript.text.strip()
        await update.message.reply_text(f"üéß –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–ª: {text}")

        fake_update = Update(update.update_id, message=update.message)
        fake_update.message.text = text
        await handle_text(fake_update, context)

    except Exception as e:
        logger.error(e)
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–∞: {e}")


# -----------------------------------------------------
# üñº –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
# -----------------------------------------------------
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        photo = await update.message.photo[-1].get_file()
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as temp_file:
            file_path = temp_file.name
            await photo.download_to_drive(custom_path=file_path)

        image = cv2.imread(file_path)
        if image is not None:
            image = cv2.convertScaleAbs(image, alpha=1.3, beta=30)
            image = cv2.GaussianBlur(image, (3, 3), 0)
            cv2.imwrite(file_path, image)

        with open(file_path, "rb") as img:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–≠–ö–ì, –∞–Ω–∞–ª–∏–∑ –∏–ª–∏ —Ä–µ–Ω—Ç–≥–µ–Ω)."},
                            {"type": "image", "image": img.read()}
                        ]
                    }
                ]
            )

        os.remove(file_path)
        reply_text = response.choices[0].message.content
        await update.message.reply_text(f"üìä {reply_text}")

        # üéß –û–∑–≤—É—á–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if context.user_data.get("voice_enabled", True):
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_audio:
                audio_path = temp_audio.name
            with client.audio.speech.with_streaming_response.create(
                model="gpt-4o-mini-tts",
                voice="verse",
                input=reply_text
            ) as stream:
                stream.stream_to_file(audio_path)

            await update.message.reply_voice(voice=InputFile(audio_path))
            os.remove(audio_path)

    except Exception as e:
        logger.error(e)
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")


# -----------------------------------------------------
# üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
# -----------------------------------------------------
def main():
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("voice_on", voice_on))
    app.add_handler(CommandHandler("voice_off", voice_off))
    app.add_handler(CallbackQueryHandler(reset))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))

    logger.info("ü§ñ –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π GPT-–±–æ—Ç –∑–∞–ø—É—â–µ–Ω —Å –æ–∑–≤—É—á–∫–æ–π.")
    app.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
